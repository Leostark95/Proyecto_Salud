{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib ### para cargar array\n",
    "\n",
    "########Paquetes para NN #########\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics ### para analizar modelo\n",
    "from sklearn.ensemble import RandomForestClassifier  ### para analizar modelo\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import tree\n",
    "import a_funciones as fn\n",
    "\n",
    "import cv2 ### para leer imagenes jpeg\n",
    "### pip install opencv-python\n",
    "\n",
    "from matplotlib import pyplot as plt #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1569/1569 [00:13<00:00, 112.16it/s]\n",
      "100%|██████████| 803/803 [00:06<00:00, 132.92it/s]\n",
      "100%|██████████| 208/208 [00:01<00:00, 137.31it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 138.99it/s]\n",
      "100%|██████████| 448/448 [00:03<00:00, 137.61it/s]\n",
      "100%|██████████| 227/227 [00:01<00:00, 128.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# cargar bases_procesadas ##\n",
    "x_train, y_train, x_test, y_test, x_val, y_val = fn.imag_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'salidas/x_train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### cargar bases_procesadas ####\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m x_train \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalidas/x_train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m y_train \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalidas/y_train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m x_test \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalidas/x_test.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'salidas/x_train.pkl'"
     ]
    }
   ],
   "source": [
    "# cargar bases_procesadas #\n",
    "\n",
    "x_train = joblib.load('salidas/x_train.pkl')\n",
    "y_train = joblib.load('salidas/y_train.pkl')\n",
    "x_test = joblib.load('salidas/x_test.pkl')\n",
    "y_test = joblib.load('salidas/y_test.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2372, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(336, 224, 224, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Escalar ######################\n",
    "x_train = x_train.astype('float32') ## para poder escalarlo\n",
    "x_test = x_test.astype('float32') ## para poder escalarlo\n",
    "x_train /= 255 ### escalaro para que quede entre 0 y 1\n",
    "x_test /= 255\n",
    "\n",
    "###### verificar tamaños\n",
    "print(x_train.shape)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150528"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.product(x_train[1].shape) ## cantidad de variables por imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1569,  803]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([208, 128]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2372, 150528)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(336, 150528)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### convertir a 1 d array ############\n",
    "x_train2 = x_train.reshape(2372,150528)\n",
    "x_test2 = x_test.reshape(336, 150528)\n",
    "print(x_train2.shape)\n",
    "x_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de métricas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: Se selecciona el Recall como métrica de rendimiento para nuestro modelo de predicción de cáncer de mama porque queremos minimizar los falsos negativos (casos en los que el modelo predice incorrectamente que una persona no tiene cáncer cuando en realidad sí lo tiene). El Recall mide la proporción de casos positivos correctamente identificados, asegurando que detectemos la mayor cantidad posible de personas con cáncer, lo cual es esencial en aplicaciones de salud donde un diagnóstico omitido puede tener consecuencias graves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC: Teniendo en cuenta que esta métrica permite obtener información sobre qué tan capaz es el modelo para identificar casos positivos vs una mala detección o calificación de negativos. Entonces, para nuestro problema, su aplicabilidad iría en determinar el porcentaje de las pacientes con cáncer de mama que el modelo logró identificar correctamenre (TP, verdaderos positivos) en comparación con aquellas que en realidad estaban sanas, pero que el modelo predice como cáncer (FP, falsos positivos).  Esta métrica es útil ya que, aunque los falsos negativos tienen un impacto alto y severo a nivel de bienestar e integridad de la persona (lo cual puede llegar a tener consecuencias graves, hasta costarle la vida); por otro lado, el hecho de tener falsos positivos, supone compromisos a nivel psicológico y costos financieros tanto para el hospital/clínica como para la paciente. Adicionalmente, en dado caso no se hagan más pruebas para descartar el cáncer de mama, recetar medicina para este tipo de patologías a personas sanas o con diagnósticos distintos puede alterar de igual forma su calidad de vida. Y supone una pérdida de credibilidad para la entidad de salud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1569\n",
      "           1       1.00      1.00      1.00       803\n",
      "\n",
      "    accuracy                           1.00      2372\n",
      "   macro avg       1.00      1.00      1.00      2372\n",
      "weighted avg       1.00      1.00      1.00      2372\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "modelo_1=RandomForestClassifier() #bosques aleatorios\n",
    "modelo_1.fit(x_train2, y_train) #entrenar modelo\n",
    "\n",
    "train_pred=modelo_1.predict(x_train2)\n",
    "print(metrics.classification_report(y_train, train_pred)) #importante el RECALL de train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La métrica AUC dio: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"La métrica AUC para entrenamiento dio: {metrics.roc_auc_score(y_train, train_pred)}\") #AUC de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.94      0.75       208\n",
      "           1       0.43      0.08      0.13       128\n",
      "\n",
      "    accuracy                           0.61       336\n",
      "   macro avg       0.53      0.51      0.44       336\n",
      "weighted avg       0.55      0.61      0.51       336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred=modelo_1.predict(x_test2)\n",
    "print(metrics.classification_report(y_test, test_pred)) #importante el RECALL de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La métrica AUC dio: 0.5078125\n"
     ]
    }
   ],
   "source": [
    "print(f\"La métrica AUC para evaluación dio: {metrics.roc_auc_score(y_test, test_pred)}\") #AUC de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelo de Redes Neuronales Estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delva\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.ravel() #convierte y_train en un arreglo unidimensional\n",
    "\n",
    "\n",
    "# Definir el modelo de red neuronal con regularización Dropout\n",
    "fc_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),  # Dropout para reducir el sobreajuste; 'apaga' el 30% de neuronas\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar el optimizador\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001) #busca minimizar la función de pérdida del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los pesos de cada clase para mejorar el aprendizaje de las clases desbalanceadas\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "#Compilar el modelo\n",
    "fc_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['Recall', 'AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 76ms/step - AUC: 0.5110 - Recall: 0.4653 - loss: 0.8581 - val_AUC: 0.5198 - val_Recall: 0.0859 - val_loss: 0.6776\n",
      "Epoch 2/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - AUC: 0.4899 - Recall: 0.4487 - loss: 0.7191 - val_AUC: 0.5231 - val_Recall: 0.4688 - val_loss: 0.6916\n",
      "Epoch 3/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - AUC: 0.4942 - Recall: 0.6712 - loss: 0.6986 - val_AUC: 0.5087 - val_Recall: 1.0000 - val_loss: 0.6949\n",
      "Epoch 4/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - AUC: 0.4869 - Recall: 0.7689 - loss: 0.6979 - val_AUC: 0.5101 - val_Recall: 0.9531 - val_loss: 0.6963\n",
      "Epoch 5/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - AUC: 0.5035 - Recall: 0.7750 - loss: 0.6902 - val_AUC: 0.4965 - val_Recall: 0.9922 - val_loss: 0.6940\n",
      "Epoch 6/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - AUC: 0.5123 - Recall: 0.9445 - loss: 0.6956 - val_AUC: 0.4973 - val_Recall: 1.0000 - val_loss: 0.6942\n",
      "Epoch 7/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - AUC: 0.5042 - Recall: 0.9743 - loss: 0.6917 - val_AUC: 0.5123 - val_Recall: 0.6641 - val_loss: 0.6911\n",
      "Epoch 8/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - AUC: 0.5071 - Recall: 0.7617 - loss: 0.6952 - val_AUC: 0.5113 - val_Recall: 0.9609 - val_loss: 0.6938\n",
      "Epoch 9/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - AUC: 0.5065 - Recall: 0.9840 - loss: 0.6980 - val_AUC: 0.5088 - val_Recall: 0.9609 - val_loss: 0.6943\n",
      "Epoch 10/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - AUC: 0.5170 - Recall: 0.9235 - loss: 0.6898 - val_AUC: 0.5030 - val_Recall: 0.7031 - val_loss: 0.6911\n",
      "Epoch 11/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - AUC: 0.4998 - Recall: 0.7752 - loss: 0.6915 - val_AUC: 0.5164 - val_Recall: 0.8203 - val_loss: 0.6922\n",
      "Epoch 12/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - AUC: 0.5214 - Recall: 0.8761 - loss: 0.7001 - val_AUC: 0.5049 - val_Recall: 0.6016 - val_loss: 0.6865\n",
      "Epoch 13/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - AUC: 0.4888 - Recall: 0.8587 - loss: 0.6952 - val_AUC: 0.4965 - val_Recall: 0.9062 - val_loss: 0.6929\n",
      "Epoch 14/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - AUC: 0.5102 - Recall: 0.8497 - loss: 0.6973 - val_AUC: 0.4993 - val_Recall: 0.9141 - val_loss: 0.6931\n",
      "Epoch 15/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - AUC: 0.5159 - Recall: 0.8874 - loss: 0.6941 - val_AUC: 0.4998 - val_Recall: 0.8047 - val_loss: 0.6920\n",
      "Epoch 16/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - AUC: 0.5354 - Recall: 0.8569 - loss: 0.6878 - val_AUC: 0.4931 - val_Recall: 0.6016 - val_loss: 0.6868\n",
      "Epoch 17/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - AUC: 0.5014 - Recall: 0.7944 - loss: 0.6867 - val_AUC: 0.4747 - val_Recall: 0.8516 - val_loss: 0.6930\n",
      "Epoch 18/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - AUC: 0.5197 - Recall: 0.9119 - loss: 0.6886 - val_AUC: 0.4988 - val_Recall: 0.7344 - val_loss: 0.6921\n",
      "Epoch 19/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - AUC: 0.5203 - Recall: 0.8813 - loss: 0.6909 - val_AUC: 0.5051 - val_Recall: 0.8281 - val_loss: 0.6936\n",
      "Epoch 20/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - AUC: 0.5283 - Recall: 0.9257 - loss: 0.6841 - val_AUC: 0.4976 - val_Recall: 0.8750 - val_loss: 0.6934\n",
      "11/11 - 0s - 14ms/step - AUC: 0.4976 - Recall: 0.8750 - loss: 0.6934\n",
      "Test recall: 0.875\n",
      "Test AUC: 0.49761494994163513\n",
      "Test loss: 0.6933674812316895\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "fc_model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,  #tamaño de lote reducido\n",
    "    epochs=20,  #mas iteraciones para una mejor convergencia\n",
    "    validation_data=(x_test, y_test),\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_recall, test_auc = fc_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Test loss:\", test_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
